# Example GitHub Actions workflow for running official benchmarks
# Rename this file to benchmark.yml and place in .github/workflows/ to enable

name: Performance Benchmark

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run weekly benchmarks on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      quick_benchmark:
        description: 'Run quick benchmark instead of full suite'
        required: false
        default: 'false'
        type: boolean

jobs:
  benchmark:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install pytest
      run: pip install pytest
    
    - name: Setup Rust
      uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        override: true
    
    - name: Cache Rust dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
    
    - name: Build release binary
      run: cargo build --release
    
    - name: Run Official Benchmark
      run: |
        if [ "${{ github.event.inputs.quick_benchmark }}" = "true" ]; then
          python scripts/official_benchmark.py --quick
        else
          python scripts/official_benchmark.py
        fi
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: |
          benchmarks/official_results.json
          docs/OFFICIAL_BENCHMARK_RESULTS.md
    
    - name: Comment benchmark results on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const path = './docs/OFFICIAL_BENCHMARK_RESULTS.md';
          
          if (fs.existsSync(path)) {
            const results = fs.readFileSync(path, 'utf8');
            const comment = `## üìä Performance Benchmark Results\n\n${results}`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          }
    
    - name: Commit updated results (main branch only)
      if: github.ref == 'refs/heads/main' && github.event_name != 'pull_request'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        if [[ -n $(git status --porcelain) ]]; then
          git add docs/OFFICIAL_BENCHMARK_RESULTS.md
          git commit -m "chore: update official benchmark results [skip ci]"
          git push
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  performance-regression-check:
    runs-on: ubuntu-latest
    needs: benchmark
    if: github.event_name == 'pull_request'
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 2  # Need previous commit for comparison
    
    - name: Download benchmark artifacts
      uses: actions/download-artifact@v3
      with:
        name: benchmark-results
    
    - name: Check for performance regression
      run: |
        # This is a placeholder for performance regression detection
        # You could implement logic to compare against baseline results
        # and fail the check if performance degrades significantly
        
        echo "Performance regression check passed"
        # Example: Compare current results with baseline
        # if [ performance_degraded_more_than_10_percent ]; then
        #   echo "‚ùå Performance regression detected!"
        #   exit 1
        # fi